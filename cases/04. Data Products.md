# **Engenharia de Dados em 5 tópicos:** 

## **4º Data Products e a fonte da verdade.**

Depois de muita teoria nos últimos textos, **a ideia é hoje materializar o que faz e como faz o profissional de engenharia de dados no seu dia a dia**.

**Se fosse para resumir** em poucas palavras **o que a engenharia de dados deve fazer seria: "se comunicar com a fonte da verdade".**

Trabalhando com estoque, o famoso controle de cargas é uma fonte da verdade. Entrar no depósito e encontrar a geladeira marcada como entregue no controle, é semelhante a um deploy na sexta feira. Uma hora se resolve, mas a chance de você ter que atuar sozinho e até mais tarde é alta. Isso vale para o fluxo de caixa, o controle de ponto (Deus viu a sua cara), e aquela query na tabela que retorna nulo.

**Em diferentes cenários a função de ~~detetive~~ engenharia de dados encontra a imprecisão nas informações que lida**, muitas vezes também a imprecisão do que de fato se está buscando. **A apuração dessas informações (tratamento, feature enginnering, o nome que preferir) é a maior parte do dia a dia da profissão**. As ferramentas abaixo buscam auxiliar essa busca da verdade e muitas vezes estabelecer o que é a verdade.

**Produto:** **_Catálogo de dados_**
**O que faz:** Busca guiar o consumos dos dados das camadas analíticas à partir das informações dos artefatos de dados (tabelas, dashboards, modelos, arquivos, ...) dessas camadas.
Um subproduto muitas vezes incluído no catálogo é a linhagem de dados. É a árvore genealógica do artefato: Tabelas, arquivos e o que mais originou o artefato, e o que o artefato originou. Deve ser o mapa do lago de dados.
**Soluções comuns:** Qlik, Oracle Cloud Infrastructure (OCI), Google Cloud, AWS Glue, Microsoft Purview, Lumada, Informatica, Apache Atlas*, Amudsen*, Datahub*, Metacat*, OpenMetadata*

**Produto:** **_Camada Semântica_**
**O que faz:** É a camada de dados tratados e estruturados, mas com a visão do negócio. Preocupada em dar sentido, padronização e aplicar regras de negócio aos dados.
Lembra do caso inicial da geladeira? Pensa que João anotou 'Entregue' no controle porque ele que recebeu a geladeira do fonecedor. A camada semântica, é o gerente que vai determinar se João fez certo ou 'Entregue' vai ser o registro quando a mercadoria foi recebida pelo cliente por exemplo.
É uma peça chave na busca da verdade nos times de dados.
**Soluções comuns:** Oracle Analytics Semantic Modeler,MicroStrategy, Dremio, AtScale, Kyligence, Tableau, MetricFlow (dbt), Data Mart (Power BI)

**Produto:** **_Data Quality_**
**O que faz:** Estabelece a tolerância à falhas para criação, atualização e consumo dos dados à partir das expectativas com ele (% de valores nulos aceitos, de campos com determinado nome, dados duplicados, etc.)
Aqui são soluções que "constróem" a verdade e reside boa parte dos esforços de transformação dos dados. Constróem porque na presençca de dados faltantes o que se faz com eles? Valores duplicados, com erros de digitação, etc.. são esperados, devem ser apagados, renomeados?
**Soluções comuns:** Todos os produtos anteriores tem iniciativas de qualidade, mas o principal é gratuito e pode ser utilizado em qualquer etapa dos dados: **Great Expectations**, lib do python que se você não conhece, dá um google agora.

**Produto:** **_Pipelines de dados_**
**O que faz:** É a automação do ETL/ELT. Não é difícil imaginar a importância disso. É o ponto de conexão de todos os outros produtos. Não dá pra ter nenhuma outra iniciativa sem dados!
**Soluções comuns:** Geralmente utiliza-se ferramentas de orquestração ou de terceiros para as pipelines. Alguns exemplos: Azure Data Factory, Dataflow (Google Cloud), AWS Glue, Astera Data Stack, Databricks Jobs, Apache NIFI*

**Produto:** **_Orquestradores_**
**O que faz:** São ferramentas que permitem a criação de pipelines de dados, mas também de processos de dados, de forma automatizada e com a possibilidade de reutilização de código.
**Soluções comuns:** A rigor, qualquer schedule pode ser usado para essas funções, mas na área de dados se destacam os seguintes: Pentaho, dbt, Apache Airflow*

**Produto:** **_Playgrounds (interfaces de cloud)_**
**O que faz:** São as interfaces de cloud que permitem a criação de ambientes de dados, com a possibilidade de criação de pipelines de dados, processos de dados, etc.
É onde a brincadeira acontece!
**Soluções comuns:** Databricks, Cloudera, Snowflake

Impossível entrar nos detalhes de todos, e é comum alguns dos "playgrounds" servirem como integradores dos outros produtos. Exemplo o Databricks que tem ferramentas para muitos dos 6 serviços apresentados.
Nesse cenário cuidado com o aprisionamento (lock-in) que é a dependência do produto para ofertar essa solução, e como para tudo dimensionar a real necessidade dos times para construção da solução mais adequada àquela necessidade.

**Stay producing!**
