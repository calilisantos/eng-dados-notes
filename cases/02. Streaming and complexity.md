# Processos streaming. Um dos "problemas" sem solução na engenharia de dados.

**A complexidade é um tema mal compreendido**, por complexo ser entedido como sinônimo de difícil, e é parte do cotidiano até da nossa casa, mas tem uma facilidade tremenda em aparecer em atividades de tecnologia.

**_Para um problema difícil existe uma solução, para um complexo é criado um processo_**. O semáforo ajuda a melhorar o fluxo de carros (uma solução). Coordenar os semáforos de toda a cidade, com gente furando o sinal, às 18:00, etc.. simplesmente não tem solução, têm-se a multa (um processo, e que processo seu prefeito...)

**_O processamento em engenharia de dados_** (detalhes aqui: <colocar link do tópico>) **_tem na definição da sua extração, se agendada (batch) ou não (streaming)_**, uma das diferenças para o estouro ou economia do orçamento da área.

**Se o ETL é agendado pode se considerar que foi encontrada uma solução**: o dado vai chegar na quantidade e hora necessária. **Batch deveria ser o caso da maioria dos processamentos, mas como streaming tá na moda, virou o patinho feio**. Seu dado streamado vai chegar ultra-mega-real-time, vai soar bonito pra chefia, vai pegar bem no Linkedin mas pode já nascer com um problema: dos arquivos miúdos (_small files problem_).

**Pensa que seu ETL é uma caneta e o armazenamento dos seus dados um caderno**. O small files problem é quando você escreve na frente da folha nas duas primeiras linhas dela. Em dois segundos você vira a folha do caderno, deixando em branco o resto da frente e seu verso inteiro, e escreve de novo nas duas primeiras linhas da folha seguinte e repete o processo indefinidamente. Não só ouve um desperdício de armazenamento (espaços em branco do caderno) mas um SELECT *, ou a leitura do caderno, vai ser mais lenta.

**Processos streaming são necessários em diversos cenários, e o small files problem é uma situação recorrente nesse tipo de processo**. É como o trânsito de São Paulo na hora do rush, não tem solução. Em um extremo você tem small files, criando diversas partições e onerando a leitura de artefatos em big data, no outro são as big files, cuja leitura é mais rápida com as ferramentas corretas, mas ocupa um maior espaço de armazenamento.

A engenharia de dados é preocupada com o meio termo desse cenário. aplicando técnicas de compressão, paralelização e distribuição para melhorar o desempenho do processamento. Adicionando mais um: processo. Para uma pipeline de criação, existem uma de limpeza e de otimização de tabelas, assim me disseram. Complexidade na veia!

Semana que vem o tema é camada analítica, ou quando a engenharia de dados quer ser gerenciadora de bancos de dados.

Stay streaming!
